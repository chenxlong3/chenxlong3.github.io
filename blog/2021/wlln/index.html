<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 弱大数定律的推导及意义 | Xiaolong Chen </title> <meta name="author" content="Xiaolong Chen"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.svg?169cce5d54035e520d22a1c86af66613"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://chenxlong3.github.io/blog/2021/wlln/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Xiaolong Chen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"> <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">弱大数定律的推导及意义</h1> <p class="post-meta"> Created on September 10, 2021 </p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/techniques"> <i class="fa-solid fa-hashtag fa-sm"></i> Techniques</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>样本数目足够多的情况下，样本均值会趋于期望。</p> <p>样本数目足够多的情况下，事件发生的频率趋于概率。</p> <p>为何两种说法都称为大数定律，样本均值与频率又到底是什么关系呢？</p> <h1 id="马尔可夫不等式-the-markov-inequality">马尔可夫不等式 (The Markov Inequality)</h1> <p>Markov Inequality描述了一个非常简单的想法：如果随机变量恒大于零，且该随机变量的期望较小，那么我们随机做一次实验，所得到的$X$也不太可能会很大。举个例子，如果全国十四亿人口的平均身高为1.67米，那么我们随机抽一个人，他/她的身高不会偏离这个数字太远，他/她的身高为2米的概率是比较低的。</p> <p>$P(X\geq a)$: 随机变量$X$不小于$a$ 的概率</p> <p>$E[X]$: 随机变量$X$的期望</p> <p>$a$: 任一正数</p> \[P(X\geq a) \leq \frac{E[X]}{a}\] <p>$Proof\ 1$:</p> \[\begin{align*} E[X] &amp;= \int^{\infty}_{-\infty} xf(x)dx\\ &amp;\geq \int^{\infty}_{a} xf(x)dx \\ &amp;\geq \int^{\infty}_{a} af(x)dx \\ &amp;= aP(X\geq a) \\ \\ P(X\geq a) &amp;\leq \frac{E[x]}{a} \end{align*}\] <p>除此之外，还有一种证明方法，但两者的内在思想是一样的，也在此简述一下。</p> <p>$Proof\ 2$:</p> <p>假设我们有另外一个随机变量$Y$，如下：</p> \[\begin{equation*} Y=\left\{ \begin{aligned} a, &amp;\quad X\geq a\\ 0, &amp;\quad X&lt;a \end{aligned} \right. \end{equation*}\] <p>显然这是一个离散型随机变量，那么我们可以用以下公式计算出它的期望：</p> \[\begin{align*} E[Y] &amp;= aP(X\geq a) + 0\cdot P(X&lt;a)\\ &amp;= aP(X\geq a) \end{align*}\] <p>因为当$X\geq a$时，$Y=a$，而当$X&lt;a$时，$Y = 0$。所以很显然可以得到：$Y\leq X$。那么也就有$E[Y] \leq E[X]$。则：</p> \[\begin{align*} E[Y] = aP(&amp;X\geq a) \leq E[X] \\ \\P(X\geq a) &amp; \leq \frac{E[X]}{a} \end{align*}\] <p>可是稍微往深处想一想，就会觉得这个不等式非常鸡肋。从不等式上来看，随机变量大于或等于$k$倍期望的概率不超过$\frac{1}{k}$。这样说或许还不直观，我们再举回那个身高的例子，全国十四亿人口的平均身高为1.67米。这个不等式告诉我们，如果随机抽一个人，他/她的身高不小于3.34米的概率不超过$1/2$……</p> <p>根据我们的常识，这个概率何止是不超过$1/2$，说是远小于1%也不为过。这其实就是这个Markov Inequality的一个缺点——它的上界定得太大了。</p> <h1 id="切比雪夫不等式-the-chebyshev-inequality">切比雪夫不等式 (The Chebyshev Inequality)</h1> <p>Chebyshev Inequality把方差也考虑了进来。这个不等式阐述的想法就是：如果一个随机变量的方差不大，那么这个随机变量不会离它的均值太远。不等式的形式如下：</p> \[\begin{align*} P(|X-\mu|\geq c)\leq \frac{\sigma^2}{c^2} \end{align*}\] <p>同样地，我们来证明一下这个不等式。</p> <p>首先，绝对值这个东西有点碍眼，它的存在往往意味着分类讨论，我们可以先把它去掉，两边同时进行平方运算。</p> \[\begin{align*} P(|X-\mu|\geq c) = P((X-\mu)^2\geq c^2) \end{align*}\] <p>然后，把$(X-\mu)^2$看作一个新的随机变量，利用Markov Inequality得到，</p> \[\begin{align*} P(|X-\mu|\geq c) = P((X-\mu)^2 \geq c^2) &amp;\leq \frac{E[(X-\mu)^2]}{c^2} = \frac{\sigma^2}{c^2} \end{align*}\] <p>证毕。</p> <p>假设平均身高为167$cm$，方差为100$cm^2$，那么抽到一个人身高大于或等于3.34米的概率会小于或等于0.0035。这样看倒也科学不少。</p> <h1 id="弱大数定律-weak-law-of-large-numbers-wlln">弱大数定律 (Weak Law of Large Numbers, WLLN)</h1> <h2 id="证明">证明</h2> <p>接着我们来看一下这篇文章真正的主角——大数定律。更准确地说，是弱大数定律，也称为辛钦大数定律。至于强大数定律，会在这篇blog的结尾提一嘴，它的证明有点超出我的知识范畴了，我也就偷个懒吧。</p> <p>先给出来大数定律的形式：</p> <p>对于任意$\epsilon &gt; 0$:</p> \[\begin{align*} P(|M_n-\mu|\geq \epsilon) \rightarrow 0, \ as\ n \rightarrow \infty \end{align*}\] <p>其中：</p> <p>$M_n$: 样本均值，计算公式为</p> \[M_n = \frac{X_1 + X_2+\cdots + X_n}{n}\] <p>$\mu$: 随机变量的期望</p> <p>$n$: 样本数量</p> <p>$X_1\cdots X_n$: 独立同分布的随机变量</p> <p>接下来我们给出弱大数定律的证明：</p> <p>$Proof: $</p> <p>根据均值及方差的线性性 (Linearity):</p> \[\begin{align*} E[M_n] &amp;= E[\frac{X_1+\cdots+X_n}{n}]\\ \\ &amp;= \frac{E[X_1]+\cdots+E[X_n]}{n}\\ \\ &amp;=\frac{n\mu}{n}\\ \\ &amp;= \mu\\ \\ \\ Var(M_n) &amp;= Var(\frac{X_1+\cdots+X_n}{n})\\ \\ &amp;= \frac{Var(X_1) + \cdots + Var(X_n)}{n^2}\\ \\ &amp;= \frac{n\sigma^2}{n^2}\\ \\ &amp;= \frac{\sigma^2}{n} \end{align*}\] <p>根据前面提到的Chebyshev Inequality，</p> \[\begin{align*} P(|M_n - \mu| \geq \epsilon) &amp;\leq \frac{Var(M_n)}{\epsilon^2} = \frac{\sigma^2}{n\epsilon^2}\\ \\ 0\leq \lim_{n \to \infty} P(|M_n - \mu| &amp;\geq \epsilon)\leq \lim_{n \to \infty} \frac{\sigma^2}{n\epsilon^2} = 0 \end{align*}\] <p>根据夹逼定理，</p> \[\begin{align*} \lim_{n \to \infty} P(|M_n - \mu| &amp;\geq \epsilon) = 0 \end{align*}\] <p>证毕。</p> <p>WLLN描述的实际上就是我们在开头讲的，样本数目足够多的情况下，样本均值会趋于期望。那这个描述样本均值的定律，是怎么和频率扯上关系的呢？</p> <h2 id="大数定律与事件概率估计">大数定律与事件概率估计</h2> <p>我们在讨论$X_1\cdots X_n$时，实际上讨论的是某一试验的多次重复。不妨用$X_i$来表示某事件$A$是否发生，即：</p> \[\begin{equation} X_i = \left\{ \begin{aligned} 1, \quad &amp;\text{if event A happens}\\ 0, \quad &amp;\text{if event A doesn't happen} \end{aligned} \right. \end{equation}\] <p>那么，经过多次重复实验，得到的样本均值实际上就是事情发生的频率。</p> \[\begin{align*} M_n &amp;= \frac{\sum^{n}_{i=1} X_i}{n} \\ &amp;= \frac{\text{the number of times that event A happens}}{n}\\ &amp;= frequency\\ \\ \mu &amp;= 1\cdot P(A)+0\cdot (1-P(A))\\ \\ &amp;=P(A) \end{align*}\] <p>所以，根据大数定律：</p> <p>\(\begin{align*} \lim_{n \to \infty} P(|M_n - \mu| &amp;\geq \epsilon) = \lim_{n \to \infty}P(frequency-P(A)) = 0 \end{align*}\) 也就是说，频率趋于概率。</p> <h1 id="强大数定律">强大数定律</h1> <p>强大数定律的数学形式如下，</p> \[\begin{align*} P(\lim_{n \to \infty} |M_n - \mu| \geq \epsilon) &amp;= 0 \end{align*}\] <p>实际上就是把极限符号给放进去了，虽然只有一点变化，但是表示的意思就更强烈了一点。</p> <blockquote> <p>弱大数定律指的是样本均值依概率收敛于期望，而强大数定律则指出样本均值几乎处处收敛于期望。</p> </blockquote> <p>至于再深一点的理解，笔者也并不太了解，还需深入学习。</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Xiaolong Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>